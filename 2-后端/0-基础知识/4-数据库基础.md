## 基础知识

### 为什么说MySQL单表行数不要超过2000w?

[为什么说MySQL单表行数不要超过2000w? - 掘金 (juejin.cn)](https://juejin.cn/post/7160487684358537246)

总结如下：

- Mysql 的表数据是以页的形式存放的，页在磁盘中不一定是连续的。

- 页的空间是 16K, 并不是所有的空间都是用来存放数据的，会有一些固定的信息，如，页头，页尾，页码，校验码等等。

- 在 B+ 树中，叶子节点和非叶子节点的数据结构是一样的，区别在于，叶子节点存放的是实际的行数据，而非叶子节点存放的是主键和页号。

  <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/45c57a7623e741cfab70b8a5d6189df0~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp" style="zoom: 67%;" />

- 行数增加后，可能会导致 B + 树层级更高，影响查询性能。例如 mysql 增加到 2kw，会出现4层的 B+ 树。

## 主库/从库

### 主从库概念

**从库**也是一个数据库，它生成两个线程，一个**I/O线程**，一个**SQL线程**；

I/O线程用来请求主库`binlog`(执行日志的二进制文件)，并将其写道`relaylog`(中继日志)中；

主库会生成一个`log dump`线程，用来给从库I/O线程传`binlog`；

SQL线程用来读取中继文件中的日志，并解析成具体操作，来实现主从的操作一致，最终数据一致。

### 主从库用途

1. 实时灾备，用于故障切换
2. 读写分离，提供查询服务（主要功能，一般是主数据库）
3. 备份，避免影响业务

### 主从库部署

#### 前提条件

首先，主从库部署需要满足以下条件：

1. 主库开启`binlog`日志（设置log-bin参数）,从库开启`relaylog`中继日志（设置relay-log参数）
2. 主从server-id不同
3. 从库服务器能连通主库

考虑到主从数据库的版本，配置都有可能不同，我们可以使用docker进行数据库配置：

#### 构建配置目录（数据存放目录）

目录结构如下：

```js
--mysql
  --master
     --data  
     --conf
        --my.cnf    
  --slave
     --data  
     --conf
        --my.cnf
```

其中`my.cng`为文件，其他均为目录。（Windows 操作系统中 MySQL 的配置文件 `my.ini`。Linux 操作系统中 MySQL 的配置文件是 `my.cnf`）

#### 配置`my.cnf`

配置文件中，我们需要注意以下几点：

1. 主从服务器的server_id需要不同且唯一，因为他是服务器的标识
2. 从服务器经常只用作读取服务
3. 有些文件需要注明忽略同步，例如`replicate-ignore-db`（忽略某库进行同步）

**Master(主数据库) `my.cnf`** 配置文件：

```
[mysqld]
server_id=1
# 要生成二进制日志文件 主服务器一定要开启
log-bin=mysql-bin
#控制binlog日志文件保留时间，超过保留时间的binlog日志会被自动删除
expire_logs_days=30
# 记录进日志的数据库，不配的话就是记录所有库
binlog-do-db=test
# 不记录进日志的数据库
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performation_schema
binlog-ignore-db=sys
# 其他需要的配置位置 无特殊需要不用
# !includedir /etc/mysql/conf.d/
# !includedir /etc/mysql/mysql.conf.d/
```

**Slave(从数据库) `my.cnf`** 配置文件：

```
[mysqld]
server_id=2
log-bin=mysql-bin
# relay-log配置中继日志
relay-log=mysql-relay-bin
# 只可以读，注意这里的只读只限制普通用户，超级用户如root还是可以写的
read-only=1
# 同步的数据库，这里我们也可以不需要，因为主数据库已经指明了需要同步的数据库
replicate-do-db=test
# 不同步的数据库 这里如果主从都没有指明需要同步的数据库，需要使用下面的配置
# replicate-ignore-db=mysql
# replicate-ignore-db=sys
# replicate-ignore-db=information_schema
# replicate-ignore-db=performance_schema
```

#### 启动docker容器

docker容器，我们选择`mysql`镜像并且使用已经建好的文件作为容器配置（使用-v命令挂载目录）。

这里，我们为了更好演示，直接使用docker启动两个容器并对外暴露不同的接口。正常做法是两个不同的服务器分别启动一个docker容器。

启动master主数据库容器：

```bash
docker run --name mastermysql -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /home/mysql_test/master/data:/var/lib/mysql -v /home/mysql_test/master/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7
```

`-e` 说明环境变量，即mysql的密码为`root`；这里 `-v` 参数，冒号前为宿主机目录，绝对路径，我们可以根据实际情况进行更改; 启动slave从数据库容器。

```bash
docker run --name slavemysql -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /home/mysql_test/slave/data:/var/lib/mysql -v /home/mysql_test/slave/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7
```

这样两个docker容器就启动了。

#### 配置docker容器

我们建立好了两个数据库，此时它们之间还没有建立好连接，我们需要配置容器。这里可以使用`Dockerfile`文件配置，也可以进入容器中使用bash命令进行配置：

master设置:

进入容器命令 docker exec -it mastermysql bash。进入容器后逐步执行以下命令：

```bash
# 进入数据库
mysql -uroot -p123456
# 这里表示创建一个slaver同步账号slave，允许访问的IP地址为%，%表示通配符，即所有地址
CREATE USER 'slave'@'%' IDENTIFIED BY '123456'; 
# 授予slave主从复制的相关权限。
GRANT REPLICATION SLAVE,REPLICATION CLIENT ON *.* to 'slave'@'%';
# 刷新权限
FLUSH PRIVILEGES;
# 创建数据库
CREATE DATABASE test;
# 查看当前master的状态
show master status;
```

mysql> show master status;
+---------------+----------+--------------+------------------+-------------------+
| File          | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+---------------+----------+--------------+------------------+-------------------+
| mysql-bin.000001|      157|              |                  |                   |
+---------------+----------+--------------+------------------+-------------------

我们需要记住此时的状态表中的File列值（例如mysql-bin.000001）和Position列的值（例如0）之后会用到。

slave设置：

进入容器命令 docker exec -it slavemysql bash。进入容器后逐步执行以下命令：

```bash
# 进入数据库
mysql -uroot -p123456
# 创建数据库
CREATE DATABASE test;
# 更改主数据库
change master to 
#主数据库ip,看情况填，如果时使用 docker-compose 可以使用容器名
master_host='mysql2',
#主数据库用户名
master_user='slave', 
#主数据库密码
master_password='123456', 
# mysql8后的密码方式，如果不是可以忽略
get_master_public_key=1,
#主数据库端口号
master_port=3306,
#日志文件开始复制数据
master_log_file='binlog.000001',
#从哪个 Position 开始读，即上文中提到的 Position 字段的值
master_log_pos=324；
# 如果连接失败，重试的时间间隔，看情况执行
# master_connect_retry=30;
```

成功执行后，在从Mysql服务器：

```bash
#启动slave
start slave;
#查看slave
show slave status\G;
```

![](https://aeiblog-1301396258.cos.ap-chengdu.myqcloud.com/img/20230124233014.png)

到此，我们的数据库主从配置就已经完成了。我们可以通过在主test数据库的添加一条记录来，在从数据库查询来验证其有效性:

回到主数据库中，增加一条记录：

docker exec -it mastermysql bash

```mysql
mysql -uroot -p123456
# 使用test数据库
use test
# 常见user表并且插入一条数据
create table user( id int(10) auto_increment, name varchar(30), primary key (id) )charset=utf8mb4;
insert into user(name) values("aaaa");
```

进入从数据库，查询记录：

```mysql
mysql -uroot -p123456
# 使用test数据库
use test
# 查看表
show tables;
# 查询记录
select * from user;

+----+------+
| id | name |
+----+------+
|  1 | aaa  |
+----+------+
```

#### 数据库同步事宜：

我们这里的情况是数据本来没有的情况，但是如果在设置主从库之前，主库已经存在了一些数据，呢么我们可以先进行数据同步：

```mysql
# 1. 登录master，执行锁表操作
mysql -uroot -p123456
FLUSH TABLES WITH READ LOCK;
exit
# 回到bash页面
# 2. 将master中需要同步的db的数据dump出来
mysqldump -uroot -p123456 test > test.sql
# 3. 将数据导入slave 106.13.39.69为从数据库所在ip，3308为端口
mysql -h106.13.39.69 -P3308  -uroot -p123456 test < test.sql
# 回到数据库中
# 4. 解锁master
mysql -uroot -p123456
UNLOCK TABLES;
```

如果由于重启导致 `Slave_SQL_Running: No`，我们可以使用以下命令：

```
stop slave ;
set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;
start slave ;
```

或者重新执行上面的从库设置主库操作。（[Slave_SQL_Running:No的两种解决办法](https://www.cnblogs.com/dannylinux/p/9816045.html)）

## 分库分表

### 为什么要分库分表

在数据量在百万级别的时候，我们可以通过增加只读从库，优化索引规则来进一步增加数据库性能；但是当数据库中需要储存的量继续增加时，就会面临**容量**和**连接数**两个难题：

- 数据库实例的容量是固定的，我们需要通过加容量的方式来解决承载不了数据的问题

- 我们可以通过`max_connections`查看MySQL最大连接数，当存在高并发场景时，很容易将连接数耗尽导致`too many connections`报错，导致后续数据库无法正常访问。

### 如何分库分表

> 分库分表的核心就是对数据的分片（`Sharding`）并相对均匀的路由在不同的库、表中，以及分片后对数据的快速定位与检索结果的整合。

分库与分表可以从：垂直（纵向）和 水平（横向）两种纬度进行拆分。下边我们以经典的订单业务举例，看看如何拆分。

![](https://aeiblog-1301396258.cos.ap-chengdu.myqcloud.com/img/20230125113406.png)

#### 垂直拆分

##### 1、垂直分库

垂直分库一般来说按照业务和功能的维度进行拆分，将不同业务数据分别放到不同的数据库中，核心理念 `专库专用`。

按业务类型对数据分离，剥离为多个数据库，像订单、支付、会员、积分相关等表放在对应的订单库、支付库、会员库、积分库。不同业务禁止跨库直连，获取对方业务数据一律通过`API`接口交互，这也是微服务拆分的一个重要依据。

![垂直分库](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3ab4abf1cb6e47fe836f686ebcc4a617~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

垂直分库很大程度上取决于业务的划分，但有时候业务间的划分并不是那么清晰，比如：电商中订单数据的拆分，其他很多业务都依赖于订单数据，有时候界线不是很好划分。

垂直分库把一个库的压力分摊到多个库，提升了一些数据库性能，但并没有解决由于单表数据量过大导致的性能问题，所以就需要配合后边的分表来解决。

##### 2、垂直分表

垂直分表针对业务上字段比较多的大表进行的，一般是把业务宽表中比较独立的字段，或者不常用的字段拆分到单独的数据表中，是一种大表拆小表的模式。

例如：一张`t_order`订单表上有几十个字段，其中订单金额相关字段计算频繁，为了不影响订单表`t_order`的性能，就可以把订单金额相关字段拆出来单独维护一个`t_order_price_expansion`扩展表，这样每张表只存储原表的一部分字段，通过订单号`order_no`做关联，再将拆分出来的表路由到不同的库中。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d050588c92b146bcb81447d1b74bdad0~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

数据库它是以行为单位将数据加载到内存中，这样拆分以后核心表大多是访问频率较高的字段，而且字段长度也都较短，因而可以加载更多数据到内存中，减少磁盘IO，增加索引查询的命中率，进一步提升数据库性能。

#### 水平拆分

上边垂直分库、垂直分表后还是会存在单库、表数据量过大的问题，当我们的应用已经无法在细粒度的垂直切分时，依旧存在单库读写、存储性能瓶颈，这时就要配合水平分库、水平分表一起了。

##### 1、水平分库

水平分库是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，以此实现水平扩展，是一种常见的提升数据库性能的方式。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/57ba0f10050e4607a09e6362f356bdfe~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

例如：`db_orde_1`、`db_order_2`两个数据库内有完全相同的`t_order`表，我们在访问某一笔订单时可以通过对订单的订单编号取模的方式 `订单编号 mod 2 （数据库实例数）` ，指定该订单应该在哪个数据库中操作。

这种方案往往能解决单库存储量及性能瓶颈问题，但由于同一个表被分配在不同的数据库中，数据的访问需要额外的路由工作，因此系统的复杂度也被提升了。

##### 2、水平分表

水平分表是在**同一个数据库内**，把一张大数据量的表按一定规则，切分成多个结构完全相同表，而每个表只存原表的一部分数据。

例如：一张`t_order`订单表有900万数据，经过水平拆分出来三个表，`t_order_1`、`t_order_2`、`t_order_3`，每张表存有数据300万，以此类推。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/96db9e54f78b45e3b2fe0a8eac091d46~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

水平分表尽管拆分了表，但子表都还是在同一个数据库实例中，只是解决了单一表数据量过大的问题，并没有将拆分后的表分散到不同的机器上，还在竞争同一个物理机的CPU、内存、网络IO等。要想进一步提升性能，就需要将拆分后的表分散到不同的数据库中，达到分布式的效果。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/68be4eafcd9241a6ac2ceca49e0647ec~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

### 数据存在哪个库的表

分库分表以后会出现一个问题，一张表会出现在多个数据库里，到底该往哪个库的哪个表里存呢？

上边我们多次提到过`一定规则` ，其实这个规则它是一种路由算法，决定了一条数据具体应该存在哪个数据库的哪张表里。

常见的有 `取模算法` 、`范围限定算法`、`范围+取模算法` 、`预定义算法`

#### 1、取模算法

关键字段取模（对hash结果取余数 hash(XXX) mod N)，N为数据库实例数或子表数量）是最为常见的一种路由方式。

以`t_order`订单表为例，先给数据库从 0 到 N-1进行编号，对 `t_order`订单表中`order_no`订单编号字段进行取模`hash(order_no) mod N`，得到余数`i`。`i=0`存第一个库，`i=1`存第二个库，`i=2`存第三个库，以此类推。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2aff167a10e41b4b845dd884c959699~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

同一笔订单数据会落在同一个库、表里，查询时用相同的规则，用`t_order`订单编号作为查询条件，就能快速的定位到数据。

优点: 实现简单，数据分布相对比较均匀，不易出现请求都打到一个库上的情况。

缺点: 取模算法对集群的伸缩支持不太友好，集群中有N个数据库实`·hash(user_id) mod N`，当某一台机器宕机，本应该落在该数据库的请求就无法得到处理，这时宕掉的实例会被踢出集群。

此时机器数减少算法发生变化`hash(user_id) mod N-1`，同一用户数据落在了在不同数据库中，等这台机器恢复，用`user_id`作为条件查询用户数据就会少一部分。

#### 2、范围限定算法

范围限定算法以某些范围字段，如`时间`或`ID区`拆分。

用户表`t_user`被拆分成`t_user_1`、`t_user_2`、`t_user_3`三张表，后续将`user_id`范围为1 ~ 1000w的用户数据放入`t_user_1`，1000~ 2000w放入`t_user_2`，2000~3000w放入`t_user_3`，以此类推。按日期范围划分同理。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a189339b2e124053a89f8689a242f6d9~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

优点:

- 单表数据量是可控的
- 水平扩展简单只需增加节点即可，无需对其他分片的数据进行迁移

缺点:

- 由于连续分片可能存在`数据热点`，比如按时间字段分片时，如果某一段时间（双11等大促）订单骤增，存11月数据的表可能会被频繁的读写，其他分片表存储的历史数据则很少被查询，导致数据倾斜，数据库压力分摊不均匀。

#### 3、范围 + 取模算法

为了避免热点数据的问题，我们可以对上范围算法优化一下

这次我们先通过范围算法定义每个库的用户表`t_user`只存1000w数据，第一个`db_order_1`库存放`userId`从1 ~ 1000w，第二个库1000~~2000w，第三个库2000~~3000w，以此类推。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/afc870522a7b4888a26a4ad7ec93b968~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

每个库里再把用户表`t_user`拆分成`t_user_1`、`t_user_2`、`t_user_3`等，对`userd`进行取模路由到对应的表中。

有效的避免数据分布不均匀的问题，数据库水平扩展也简单，直接添加实例无需迁移历史数据。

#### 4、地理位置分片

地理位置分片其实是一个更大的范围，按城市或者地域划分，比如华东、华北数据放在不同的分片库、表。

#### 5、预定义算法

预定义算法是事先已经明确知道分库和分表的数量，可以直接将某类数据路由到指定库或表中，查询的时候亦是如此。

### 分库分表出来的问题

了解了上边分库分表的拆分方式不难发现，相比于拆分前的单库单表，系统的数据存储架构演变到现在已经变得非常复杂。看几个具有代表性的问题，比如：

#### 分页、排序、跨节点联合查询

分页、排序、联合查询，这些看似普通，开发中使用频率较高的操作，在分库分表后却是让人非常头疼的问题。把分散在不同库中表的数据查询出来，再将所有结果进行汇总合并整理后提供给用户。

比如：我们要查询11、12月的订单数据，如果两个月的数据是分散到了不同的数据库实例，则要查询两个数据库相关的数据，在对数据合并排序、分页，过程繁琐复杂。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a2fa49b04940486f9222239744edce0a~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

#### 事务一致性

分库分表后由于表分布在不同库中，不可避免会带来跨库事务问题。后续会分别以阿里的`Seata`和MySQL的`XA`协议实现分布式事务，用来比较各自的优势与不足。

#### 全局唯一的主键

分库分表后数据库表的主键ID业务意义就不大了，因为无法在标识唯一一条记录，例如：多张表`t_order_1`、`t_order_2`的主键ID全部从1开始会重复，此时我们需要主动为一条记录分配一个ID，这个全局唯一的ID就叫`分布式ID`，发放这个ID的系统通常被叫发号器。

#### 多数据库高效治理

对多个数据库以及库内大量分片表的高效治理，是非常有必要，因为像某宝这种大厂一次大促下来，订单表可能会被拆分成成千上万个`t_order_n`表，如果没有高效的管理方案，手动建表、排查问题是一件很恐怖的事。

#### 历史数据迁移

分库分表架构落地以后，首要的问题就是如何平滑的迁移历史数据，增量数据和全量数据迁移，这又是一个比较麻烦的事情，后边详细讲。

### 分库分表架构模式

分库分表架构主要有两种模式：`client`客户端模式和`proxy`代理模式

#### 客户模式

`client`模式指分库分表的逻辑都在你的系统应用内部进行控制，应用会将拆分后的SQL直连多个数据库进行操作，然后本地进行数据的合并汇总等操作。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/976776ca92914e4c95fe9e9499474a1c~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

#### 代理模式

`proxy`代理模式将应用程序与MySQL数据库隔离，业务方的应用不在需要直连数据库，而是连接proxy代理服务，代理服务实现了MySQL的协议，对业务方来说代理服务就是数据库，它会将SQL分发到具体的数据库进行执行，并返回结果。该服务内有分库分表的配置，根据配置自动创建分片表。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d0054da77faa49b5b525d206761cf5a9~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

#### 如何抉择

如何选择`client`模式和`proxy`模式，我们可以从以下几个方面来简单做下比较。

##### 1、性能

性能方面`client`模式表现的稍好一些，它是直接连接MySQL执行命令； `proxy`代理服务则将整个执行链路延长了，应用->代理服务->MySQL，可能导致性能有一些损耗，但两者差距并不是非常大。

##### 2、复杂度

`client`模式在开发使用通常引入一个jar可以； `proxy`代理模式则需要搭建单独的服务，有一定的维护成本，既然是服务那么就要考虑高可用，毕竟应用的所有SQL都要通过它转发至MySQL。

##### 3、升级

`client`模式分库分表一般是依赖基础架构团队的Jar包，一旦有版本升级或者Bug修改，所有应用到的项目都要跟着升级。小规模的团队服务少升级问题不大，如果是大公司服务规模大，且涉及到跨多部门，那么升级一次成本就比较高；

`proxy`模式在升级方面优势很明显，发布新功能或者修复Bug，只要重新部署代理服务集群即可，业务方是无感知的，但要保证发布过程中服务的可用性。

##### 4、治理、监控

`client`模式由于是内嵌在应用内，应用集群部署不太方便统一处理；`proxy`模式在对SQL限流、读写权限控制、监控、告警等服务治理方面更优雅一些。



## mysql用户指定权限

[如何给mysql用户分配权限+增、删、改、查mysql用户 - 小魚人 - 博客园 (cnblogs.com)](https://www.cnblogs.com/cyl048/p/7992376.html)

总结：

一般普通用户只有增删改查。

收回权限：`revoke all on *.* from 'xiaogang' @'%';` 这里的第一个*是库第二个是表

配置一个增删改查权限的user：`grant select,insert,update,delete on *.* to 'aei'@'%';`

新增一个增删改查权限的user：`grant select,insert,update,delete on *.* to user1@localhost Identified by "password1";`

**tips：**对于一个只读(read-only=1)的数据库，即使一个配置了增删改查的普通用户也不能对数据库进行更改